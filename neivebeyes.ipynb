{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holdout method is a model evaluation technique where the dataset is split into two subsets: a training set and a validation set. The advantages of the holdout method are its simplicity and speed. However, it may result in high variance due to the dependency on a single validation set and may not effectively capture the model's performance on unseen data.\n",
    "\n",
    "Model evaluation with validation involves splitting the dataset into three subsets: a training set, a validation set, and a test set. The training set is used to train the model, the validation set is used to tune hyperparameters and assess model performance, and the test set is used for final evaluation. The advantages of this approach include better estimation of model performance on unseen data, the ability to fine-tune hyperparameters, and reduced risk of overfitting. However, it requires a larger dataset, adds additional computational complexity, and may introduce bias if the validation set is not representative of the overall data distribution. It strikes a balance between simplicity and accuracy compared to other evaluation techniques like cross-validation.\n",
    "\n",
    "\n",
    "\n",
    "Kewan Sulaiman Saleh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4909 entries, 0 to 5109\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 4909 non-null   int64  \n",
      " 1   gender             4909 non-null   int64  \n",
      " 2   age                4909 non-null   float64\n",
      " 3   hypertension       4909 non-null   int64  \n",
      " 4   heart_disease      4909 non-null   int64  \n",
      " 5   ever_married       4909 non-null   int64  \n",
      " 6   work_type          4909 non-null   int64  \n",
      " 7   Residence_type     4909 non-null   int64  \n",
      " 8   avg_glucose_level  4909 non-null   float64\n",
      " 9   bmi                4909 non-null   float64\n",
      " 10  smoking_status     4909 non-null   int64  \n",
      " 11  stroke             4909 non-null   int64  \n",
      "dtypes: float64(3), int64(9)\n",
      "memory usage: 498.6 KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_df = pd.read_csv('stroke-data.csv')\n",
    "#deleting missing values\n",
    "new_df = new_df.dropna()\n",
    "new_df = new_df.fillna('')\n",
    "\n",
    "#remove duplicates\n",
    "new_df = new_df.drop_duplicates()\n",
    "\n",
    "\n",
    "d_list = new_df.select_dtypes(include = ['object']).columns.tolist()\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "for i in d_list:\n",
    "    le.fit(new_df[i])\n",
    "    new_df[i] = le.transform(new_df[i])\n",
    "\n",
    "\n",
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.dropna()\n",
    "X = new_df.drop(\"stroke\", axis=1)\n",
    "y = new_df[\"stroke\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.34,train_size=0.66, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Instantiate the k-NN classifier\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "# Step 5: Train the k-NN model\n",
    "y_pred = naive_bayes.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#plt.figure(figsize=(12, 12))\n",
    "#plot_tree(clf, feature_names=X.columns, class_names=['No Stroke', 'Stroke'], filled=True, rounded=True)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9161676646706587\n",
      "Precision: 0.19148936170212766\n",
      "Recall: 0.21951219512195122\n",
      "F1-score: 0.20454545454545456\n"
     ]
    }
   ],
   "source": [
    "#accuracy metrces \n",
    "naive_bayes.fit(X_train, y_train)\n",
    "# Step 5: Train the k-NN model\n",
    "y_pred = naive_bayes.predict(X_test)\n",
    "\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "\n",
    "# Calculate true positives, false positives, and false negatives\n",
    "tp = ((y_pred == 1) & (y_test == 1)).sum()\n",
    "tn = ((y_pred == 0) & (y_test == 0)).sum()\n",
    "fp = ((y_pred == 1) & (y_test == 0)).sum()\n",
    "fn = ((y_pred == 0) & (y_test == 1)).sum()\n",
    "\n",
    "# Calculate precision\n",
    "precision = tp / (tp + fp)\n",
    "\n",
    "# Calculate recall\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "# Calculate F1-score\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9232022815237318\n",
      "Precision: 0.17938931297709923\n",
      "Recall: 0.22488038277511965\n",
      "F1-score: 0.19957537154989388\n"
     ]
    }
   ],
   "source": [
    "# Perform 3-fold cross-validation and obtain predicted labels\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "naive_bayes2 = GaussianNB()\n",
    "\n",
    "predicted = cross_val_predict(naive_bayes2, X, y, cv=3)\n",
    "\n",
    "# Calculate the confusion matrix for each fold\n",
    "confusion_matrices = []\n",
    "accuracy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "f1_score=[]\n",
    "for fold in range(3):\n",
    "    cm = confusion_matrix(y, predicted)\n",
    "    confusion_matrices.append(cm)\n",
    "\n",
    "# Calculate TP, TN, FP, FN for each fold\n",
    "for fold, cm in enumerate(confusion_matrices):\n",
    "    tp = cm[1, 1]\n",
    "    tn = cm[0, 0]\n",
    "    fp = cm[0, 1]\n",
    "    fn = cm[1, 0]\n",
    "    ac=(tp+tn)/(tp+tn+fn+fp)\n",
    "    accuracy.append(ac)\n",
    "    precision.append(tp / (tp + fp))\n",
    "    recall.append( tp / (tp + fn))\n",
    "    p=(tp / (tp + fp))\n",
    "    r=tp / (tp + fn)\n",
    "    score=2 * (p * r) / (p + r)\n",
    "    f1_score.append(score)     \n",
    "\n",
    "print(\"Accuracy:\", np.mean(accuracy))\n",
    "print(\"Precision:\", np.mean(precision))\n",
    "print(\"Recall:\", np.mean(recall))\n",
    "print(\"F1-score:\", np.mean(f1_score))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: The result of 3 fold validation reliable than hold-out, because iterate the training and testing three times, the place of test and train changed 3 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9234059889997963\n",
      "Precision: 0.1776061776061776\n",
      "Recall: 0.2200956937799043\n",
      "F1-score: 0.19658119658119658\n"
     ]
    }
   ],
   "source": [
    "# Perform 5-fold cross-validation and obtain predicted labels\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "naive_bayes3 = GaussianNB()\n",
    "\n",
    "predicted = cross_val_predict(naive_bayes3, X, y, cv=5)\n",
    "\n",
    "# Calculate the confusion matrix for each fold\n",
    "confusion_matrices = []\n",
    "accuracy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "f1_score=[]\n",
    "for fold in range(5):\n",
    "    cm = confusion_matrix(y, predicted)\n",
    "    confusion_matrices.append(cm)\n",
    "\n",
    "# Calculate TP, TN, FP, FN for each fold\n",
    "for fold, cm in enumerate(confusion_matrices):\n",
    "    tp = cm[1, 1]\n",
    "    tn = cm[0, 0]\n",
    "    fp = cm[0, 1]\n",
    "    fn = cm[1, 0]\n",
    "    ac=(tp+tn)/(tp+tn+fn+fp)\n",
    "    accuracy.append(ac)\n",
    "    precision.append(tp / (tp + fp))\n",
    "    recall.append( tp / (tp + fn))\n",
    "    p=(tp / (tp + fp))\n",
    "    r=tp / (tp + fn)\n",
    "    score=2 * (p * r) / (p + r)\n",
    "    f1_score.append(score)     \n",
    "\n",
    "print(\"Accuracy:\", np.mean(accuracy))\n",
    "print(\"Precision:\", np.mean(precision))\n",
    "print(\"Recall:\", np.mean(recall))\n",
    "print(\"F1-score:\", np.mean(f1_score))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: The result of 5 fold validation reliable than hold-out, because iterate the training and testing five times, the place of test and train changed 5 times, the test set change the palce in the dataset five times with diffrent data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two  ways to improve the Naive Bayes algorithm are:\n",
    "\n",
    "1-Handle class imbalance: If the dataset has imbalanced classes, consider applying techniques like oversampling (e.g., SMOTE) or undersampling to balance the class distribution. This can help improve the model's performance, especially if the minority class is important.\n",
    "\n",
    "2-Hyperparameter tuning: Experiment with different hyperparameter settings for the Naive Bayes classifier. You can use techniques like grid search or random search to find the \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.925748502994012\n",
      "Precision: 0.18181818181818182\n",
      "Recall: 0.14634146341463414\n",
      "F1-score: 0.16216216216216217\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Create a Naive Bayes classifier\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "#Solove inbalancing in the dataset\n",
    "smt = SMOTE(random_state = 0)\n",
    "x_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7]  # Example list of hyperparameter values to try\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=naive_bayes, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calculate true positives, false positives, and false negatives\n",
    "tn = cm[0, 0]\n",
    "fp = cm[0, 1]\n",
    "fn = cm[1, 0]\n",
    "tp = cm[1, 1]\n",
    "# Calculate precision\n",
    "precision = tp / (tp + fp)\n",
    "# Calculate recall\n",
    "recall = tp / (tp + fn)\n",
    "# Calculate F1-score\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of Naive algorithm improved by using hyperparmmeter tuning and inblance smoothing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
